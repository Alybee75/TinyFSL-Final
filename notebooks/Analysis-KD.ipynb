{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6634eee0",
   "metadata": {},
   "source": [
    "# Predictions of Gloss-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01abecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_data(log_file_path):\n",
    "    with open(log_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "\n",
    "    # Process each line to extract only the part after \":\\t\"\n",
    "    for i in range(len(lines) - 1):\n",
    "        if 'Text Reference' in lines[i]:\n",
    "            reference_part = lines[i].split(':\\t', 1)[1].strip()\n",
    "            hypothesis_part = lines[i + 1].split(':\\t', 1)[1].strip()\n",
    "            references.append(reference_part)\n",
    "            hypotheses.append(hypothesis_part)\n",
    "\n",
    "    return references, hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2384e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\" Removes all non-alphanumeric characters from text, except spaces. \"\"\"\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb57c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_predictions(references, hypotheses):\n",
    "    exact_correct_predictions = {}\n",
    "    loose_correct_predictions = {}\n",
    "    incorrect_predictions = {}\n",
    "    sen_length = []\n",
    "\n",
    "    for reference, hypothesis in zip(references, hypotheses):\n",
    "        ref_words = reference.split()\n",
    "        hyp_words = hypothesis.split()\n",
    "        hyp_words_set = set(hyp_words)  # Using a set for fast membership checking\n",
    "        correct = False\n",
    "\n",
    "        for word in ref_words:\n",
    "            if word in hyp_words:\n",
    "                loose_correct_predictions[word] = loose_correct_predictions.get(word, 0) + 1\n",
    "                correct = True\n",
    "            if word not in hyp_words_set:\n",
    "                incorrect_predictions[word] = incorrect_predictions.get(word, 0) + 1\n",
    "\n",
    "        # Analyzing exact word positions\n",
    "        min_length = min(len(ref_words), len(hyp_words))\n",
    "        for i in range(min_length):\n",
    "            if ref_words[i] == hyp_words[i]:\n",
    "                exact_correct_predictions[ref_words[i]] = exact_correct_predictions.get(ref_words[i], 0) + 1\n",
    "                correct = True\n",
    "                \n",
    "        if correct:\n",
    "            temp = clean_text(reference).split()\n",
    "            sen_length.append(len(temp))\n",
    "\n",
    "    return exact_correct_predictions, loose_correct_predictions, incorrect_predictions, sen_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c501cf",
   "metadata": {},
   "source": [
    "## Combined Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8b368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = 'T=3, a=0.5/combined_kd_3,0.5.log'  \n",
    "references, hypotheses = extract_data(log_file_path)\n",
    "exact_correct_predictions, loose_correct_predictions, incorrect_predictions, length = analyze_predictions(references, hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dea94d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230 230\n"
     ]
    }
   ],
   "source": [
    "print(len(references), len(hypotheses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6969cec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*** *** saturday',\n",
       " '*** *** yellow',\n",
       " '*** *** mother',\n",
       " '*** *** october',\n",
       " 'the show is  amazing.',\n",
       " 'person in a   wheelchair',\n",
       " '** *** february',\n",
       " '* good noon!',\n",
       " 'i  am  fine',\n",
       " '** *** married',\n",
       " '* ** ** blind',\n",
       " '* ** ** slow',\n",
       " '* how are you',\n",
       " '* ** ** son',\n",
       " '* ** ** white',\n",
       " '**** daughter',\n",
       " '**** beer',\n",
       " '**** yesterday',\n",
       " '**** father',\n",
       " '**** monday',\n",
       " '*** *** green',\n",
       " '*** *** meat',\n",
       " '*** *** dark',\n",
       " '*** *** white',\n",
       " '*** *** two',\n",
       " '* ** brown',\n",
       " '* ** tomorrow',\n",
       " '* no sugar',\n",
       " 'i saw a  ghost.',\n",
       " '* good morning',\n",
       " 'my dog died.',\n",
       " 'brown',\n",
       " 'fish',\n",
       " 'i like you very much.',\n",
       " 'red',\n",
       " '*** *** tuesday',\n",
       " '*** *** juice',\n",
       " '*** *** september',\n",
       " '*** *** understand',\n",
       " '*** *** mother',\n",
       " '* ** april',\n",
       " '* ** mother',\n",
       " '* ** pink',\n",
       " 'do not know',\n",
       " '* ** spaghetti',\n",
       " '* ** ten',\n",
       " 'i hate you!',\n",
       " 'how are you?',\n",
       " 'happy new year!',\n",
       " 'our team won!',\n",
       " '* ** ** ***** brown',\n",
       " '* ** ** ***** chicken',\n",
       " 'i do not like you.',\n",
       " 'i am   scared.',\n",
       " '* ** ** ***** violet',\n",
       " 'i am   nervous.',\n",
       " '**** auntie',\n",
       " '**** six',\n",
       " 'i like you very much.',\n",
       " '**** woman',\n",
       " 'no   sugar',\n",
       " '* ** ***** good noon!',\n",
       " '* ** happy new year!',\n",
       " '**** coffee',\n",
       " '**** grandfather',\n",
       " '* ** july',\n",
       " 'my head is very painful.',\n",
       " '* ** july',\n",
       " 'i am fine.',\n",
       " '* ** son',\n",
       " '**** rice',\n",
       " '**** hot',\n",
       " '**** march',\n",
       " 'i am   worried.',\n",
       " 'see you  tomorrow',\n",
       " '* ** april',\n",
       " '* ** green',\n",
       " 'i am so tired.',\n",
       " '* ** two',\n",
       " 'i am 12 years old.',\n",
       " '* this is    very hard.',\n",
       " '* ** february',\n",
       " '* ** yesterday',\n",
       " 'i am proud of you!',\n",
       " 'my head is not painful.',\n",
       " 'i ** failed the exam.',\n",
       " '* ** yellow',\n",
       " 'i am ***** ** worried.',\n",
       " '* ** slow',\n",
       " '* ** nine',\n",
       " '*** *** white',\n",
       " '* ** good noon!',\n",
       " '*** *** sunday',\n",
       " '*** *** december',\n",
       " '*** i   am alone.',\n",
       " 'my dog died.',\n",
       " '* thank you',\n",
       " 'our team won!',\n",
       " '* ** ten',\n",
       " '* ** blind',\n",
       " '* ** parents',\n",
       " 'you are disgusting!',\n",
       " 'i am shocked!',\n",
       " 'i am not tired.',\n",
       " 'i am sorry.',\n",
       " '* no sugar',\n",
       " 'i am fine',\n",
       " '* ** yes',\n",
       " '* ** gray',\n",
       " '* good evening',\n",
       " '* thank you',\n",
       " '* the trip  is exciting.',\n",
       " '* ** deaf',\n",
       " 'i am ***** ** tired.',\n",
       " '* ** juice',\n",
       " 'i am fine.',\n",
       " '* ** august',\n",
       " '* ** fast',\n",
       " '* ** coffee',\n",
       " '* ** wrong',\n",
       " 'correct',\n",
       " 'man',\n",
       " 'fish',\n",
       " 'september',\n",
       " 'correct',\n",
       " '**** dark',\n",
       " 'thank you',\n",
       " '**** woman',\n",
       " 'do not  understand',\n",
       " 'i am   shocked!',\n",
       " '* ** light',\n",
       " 'you are not slow.',\n",
       " '* ** beer',\n",
       " '* ** yes',\n",
       " '* ** eight',\n",
       " 'i am ***** ** worried.',\n",
       " 'no sugar',\n",
       " 'deaf',\n",
       " 'i am ***** ** tired.',\n",
       " 'wednesday',\n",
       " 'the trip is exciting.',\n",
       " '* ** longanisa',\n",
       " '* you are   not slow.',\n",
       " '* ** ***** thank you.',\n",
       " '* good afternoon',\n",
       " '* ** wine',\n",
       " '* ** blind',\n",
       " '* ** hello',\n",
       " '* ** hot',\n",
       " 'you are slow.',\n",
       " 'i am nervous.',\n",
       " '**** no',\n",
       " '**** dark',\n",
       " 'good morning',\n",
       " '**** tuesday',\n",
       " '**** rice',\n",
       " '**** june',\n",
       " 'do not  understand',\n",
       " '**** married',\n",
       " '**** november',\n",
       " '**** six',\n",
       " 'nice to meet you',\n",
       " '**** october',\n",
       " '**** auntie',\n",
       " '**** october',\n",
       " 'my head is not  painful.',\n",
       " 'happy new  year!',\n",
       " 'cousin',\n",
       " 'the trip is   exciting.',\n",
       " 'pink',\n",
       " '* deaf blind',\n",
       " '* ** deaf',\n",
       " '* ** yellow',\n",
       " '* ** october',\n",
       " '* ** longanisa',\n",
       " '*** *** seven',\n",
       " 'happy new year!',\n",
       " '*** *** sunday',\n",
       " '*** *** shrimp',\n",
       " '*** *** orange',\n",
       " '* ** chicken',\n",
       " 'does john like mary?',\n",
       " '* ** eight',\n",
       " '* ** eight',\n",
       " '* ** october',\n",
       " 'does john like mary?',\n",
       " '**** parents',\n",
       " '**** light',\n",
       " 'deaf blind',\n",
       " '**** thursday',\n",
       " 'my head is very  painful.',\n",
       " '* ** cold',\n",
       " '* ** bread',\n",
       " '* ** june',\n",
       " '* ** brown',\n",
       " '* ** december',\n",
       " '* ** august',\n",
       " '* ** sunday',\n",
       " 'my head is very painful.',\n",
       " '* ** crab',\n",
       " 'i am not tired.',\n",
       " 'how are you?',\n",
       " '* ** sugar',\n",
       " '* ** october',\n",
       " '* ** friday',\n",
       " '* ** wine',\n",
       " '* ** beer',\n",
       " '* ** coffee',\n",
       " '* ** no',\n",
       " '* ** nine',\n",
       " 'grandmother',\n",
       " 'parents',\n",
       " 'married',\n",
       " 'november',\n",
       " 'my head is not  painful.',\n",
       " 'my dog died.',\n",
       " '* deaf blind',\n",
       " '* ** tea',\n",
       " '* ** february',\n",
       " '* ** yes',\n",
       " '**** saturday',\n",
       " 'happy new  year!',\n",
       " '**** man',\n",
       " '**** uncle',\n",
       " 'john likes mary.',\n",
       " 'my dog died.',\n",
       " '* ** yesterday',\n",
       " 'do not know',\n",
       " '* ** november',\n",
       " 'i saw a  ghost.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55200d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you are you',\n",
       " 'you are you',\n",
       " 'you are you',\n",
       " 'you are you',\n",
       " '*** you  are welcome',\n",
       " '****** do not know',\n",
       " 'do not know',\n",
       " 'i am   heartbroken.',\n",
       " 'do not know',\n",
       " 'do not know',\n",
       " 'i am 12 old.',\n",
       " 'i am 12 old.',\n",
       " 'i am  12  old.',\n",
       " 'i am 12 old.',\n",
       " 'i am 12 old.',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'you are welcome',\n",
       " 'you are welcome',\n",
       " 'you are welcome',\n",
       " 'you are welcome',\n",
       " 'you are welcome',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i *** am scared.',\n",
       " 'i am   fine',\n",
       " '** *** fast',\n",
       " 'fast',\n",
       " 'fast',\n",
       " 'i **** *** am   shocked!',\n",
       " 'fast',\n",
       " 'how are you?',\n",
       " 'how are you?',\n",
       " 'how are you?',\n",
       " 'how are you?',\n",
       " 'how are you?',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i  am  fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am   worried.',\n",
       " 'i   am  worried.',\n",
       " 'i     am  worried.',\n",
       " 'i   am   worried.',\n",
       " 'i am 12 years old.',\n",
       " 'i am 12 years old.',\n",
       " 'i ** *** am   sorry.',\n",
       " '* good afternoon',\n",
       " 'i am 12 years old.',\n",
       " '* good morning!',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " '* **** *** good noon!',\n",
       " 'good afternoon',\n",
       " 'good evening',\n",
       " 'i am proud of   you!',\n",
       " 'i am proud of  you!',\n",
       " 'good evening',\n",
       " 'good evening',\n",
       " 'i am fine',\n",
       " '** **** i  am   tired.',\n",
       " 'i am fine',\n",
       " 'i am tired.',\n",
       " 'i am fine',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " '* good morning!',\n",
       " '*** good afternoon',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am ** fine',\n",
       " 'i am fine',\n",
       " 'i am ** ***** tired.',\n",
       " 'i am   proud of   you!',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am proud of you!',\n",
       " '** **** i  am  fine',\n",
       " 'i am proud  of  you!',\n",
       " 'i am fine',\n",
       " 'i am proud of you!',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'you are welcome',\n",
       " 'i am so   tired.',\n",
       " 'you are welcome',\n",
       " 'you are welcome',\n",
       " 'you are so slow!',\n",
       " 'i  am  alone.',\n",
       " 'i am    fine',\n",
       " 'i   am   alone.',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i   am  scared.',\n",
       " 'i am scared.',\n",
       " 'i am *** fine',\n",
       " 'i am shocked!',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am   fine',\n",
       " 'i am    fine',\n",
       " 'i am  proud of you!',\n",
       " 'i am fine',\n",
       " 'i am proud of you!',\n",
       " 'i am fine',\n",
       " 'i am worried.',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'good afternoon',\n",
       " 'good  afternoon',\n",
       " 'good afternoon',\n",
       " '** good afternoon',\n",
       " '* good morning!',\n",
       " 'i am fine',\n",
       " '*** i   am  alone.',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am proud of you!',\n",
       " 'no *****',\n",
       " 'no',\n",
       " 'i am proud of you!',\n",
       " 'no',\n",
       " '*** i    am fine',\n",
       " 'i am fine',\n",
       " 'i am  proud of  you!',\n",
       " 'i am proud of    you!',\n",
       " 'i am   fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i   am  nervous.',\n",
       " 'i am scared.',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good evening',\n",
       " 'good evening',\n",
       " '** good evening',\n",
       " 'good evening',\n",
       " 'good evening',\n",
       " 'good afternoon',\n",
       " '**** ** good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " '** **** ** good morning!',\n",
       " '***** good evening',\n",
       " 'no',\n",
       " '*** **** good evening',\n",
       " 'no',\n",
       " 'i am   fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'you are welcome',\n",
       " 'i     am  fine',\n",
       " 'you are welcome',\n",
       " 'you are welcome',\n",
       " 'you are welcome',\n",
       " 'i am fine',\n",
       " '**** i    am   fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " '**** **** good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'i  am   12 years old.',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " '** **** i  am   shocked!',\n",
       " 'i am fine',\n",
       " 'i am *** scared.',\n",
       " 'i   am  scared.',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " '** **** ** good morning!',\n",
       " 'i  am  shocked!',\n",
       " 'i am   fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'good afternoon',\n",
       " '***** good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " '**** good  afternoon',\n",
       " 'i  am  shocked!',\n",
       " 'i am fine',\n",
       " 'i  am  fine',\n",
       " 'i am fine',\n",
       " 'i *** am shocked!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "529df478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Correct Predictions:\n",
      "i: 21\n",
      "am: 15\n",
      "proud: 1\n",
      "of: 1\n",
      "you!: 1\n",
      "fine: 1\n",
      "no: 1\n",
      "good: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact Correct Predictions:\")\n",
    "for word, count in exact_correct_predictions.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1d25bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose Correct Predictions (word found anywhere in the sentence):\n",
      "i: 21\n",
      "am: 15\n",
      "proud: 1\n",
      "of: 1\n",
      "you!: 1\n",
      "fine: 1\n",
      "no: 1\n",
      "good: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Loose Correct Predictions (word found anywhere in the sentence):\")\n",
    "for word, count in loose_correct_predictions.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a18984a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Incorrect Predictions:\n",
      "***: 45\n",
      "saturday: 2\n",
      "yellow: 3\n",
      "mother: 3\n",
      "october: 6\n",
      "the: 5\n",
      "show: 1\n",
      "is: 11\n",
      "amazing.: 1\n",
      "person: 1\n",
      "in: 1\n",
      "a: 3\n",
      "wheelchair: 1\n",
      "**: 92\n",
      "february: 3\n",
      "*: 92\n",
      "good: 6\n",
      "noon!: 3\n",
      "i: 7\n",
      "am: 6\n",
      "fine: 1\n",
      "married: 3\n",
      "blind: 6\n",
      "slow: 2\n",
      "how: 3\n",
      "are: 7\n",
      "you: 12\n",
      "son: 2\n",
      "white: 3\n",
      "****: 32\n",
      "daughter: 1\n",
      "beer: 3\n",
      "yesterday: 3\n",
      "father: 1\n",
      "monday: 1\n",
      "green: 2\n",
      "meat: 1\n",
      "dark: 3\n",
      "two: 2\n",
      "brown: 4\n",
      "tomorrow: 2\n",
      "no: 5\n",
      "sugar: 5\n",
      "saw: 2\n",
      "ghost.: 2\n",
      "morning: 2\n",
      "my: 10\n",
      "dog: 4\n",
      "died.: 4\n",
      "fish: 2\n",
      "like: 5\n",
      "very: 6\n",
      "much.: 2\n",
      "red: 1\n",
      "tuesday: 2\n",
      "juice: 2\n",
      "september: 2\n",
      "understand: 3\n",
      "april: 2\n",
      "pink: 2\n",
      "do: 5\n",
      "not: 12\n",
      "know: 2\n",
      "spaghetti: 1\n",
      "ten: 2\n",
      "hate: 1\n",
      "you!: 1\n",
      "you?: 2\n",
      "happy: 5\n",
      "new: 5\n",
      "year!: 5\n",
      "our: 2\n",
      "team: 2\n",
      "won!: 2\n",
      "*****: 9\n",
      "chicken: 2\n",
      "you.: 2\n",
      "scared.: 1\n",
      "violet: 1\n",
      "nervous.: 2\n",
      "auntie: 2\n",
      "six: 2\n",
      "woman: 2\n",
      "coffee: 3\n",
      "grandfather: 1\n",
      "july: 2\n",
      "head: 6\n",
      "painful.: 6\n",
      "fine.: 2\n",
      "rice: 2\n",
      "hot: 2\n",
      "march: 1\n",
      "worried.: 3\n",
      "see: 1\n",
      "so: 1\n",
      "tired.: 5\n",
      "12: 1\n",
      "years: 1\n",
      "old.: 1\n",
      "this: 1\n",
      "hard.: 1\n",
      "failed: 1\n",
      "exam.: 1\n",
      "nine: 2\n",
      "sunday: 3\n",
      "december: 2\n",
      "alone.: 1\n",
      "thank: 4\n",
      "parents: 3\n",
      "disgusting!: 1\n",
      "shocked!: 2\n",
      "sorry.: 1\n",
      "yes: 3\n",
      "gray: 1\n",
      "evening: 1\n",
      "trip: 3\n",
      "exciting.: 3\n",
      "deaf: 6\n",
      "august: 2\n",
      "fast: 1\n",
      "wrong: 1\n",
      "correct: 2\n",
      "man: 2\n",
      "light: 2\n",
      "slow.: 3\n",
      "eight: 3\n",
      "wednesday: 1\n",
      "longanisa: 2\n",
      "afternoon: 1\n",
      "wine: 2\n",
      "hello: 1\n",
      "june: 2\n",
      "november: 3\n",
      "nice: 1\n",
      "to: 1\n",
      "meet: 1\n",
      "cousin: 1\n",
      "seven: 1\n",
      "shrimp: 1\n",
      "orange: 1\n",
      "does: 2\n",
      "john: 3\n",
      "mary?: 2\n",
      "thursday: 1\n",
      "cold: 1\n",
      "bread: 1\n",
      "crab: 1\n",
      "friday: 1\n",
      "grandmother: 1\n",
      "tea: 1\n",
      "uncle: 1\n",
      "likes: 1\n",
      "mary.: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIncorrect Predictions:\")\n",
    "for word, count in incorrect_predictions.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69fe3f21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Correct Predictions / (Correct + Incorrect) for Each Word:\n",
      "no: 1 / 6\n",
      "good: 1 / 7\n",
      "i: 21 / 28\n",
      "fine: 1 / 2\n",
      "of: 1 / 1\n",
      "proud: 1 / 1\n",
      "you!: 1 / 2\n",
      "am: 15 / 21\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact Correct Predictions / (Correct + Incorrect) for Each Word:\")\n",
    "\n",
    "for word in set(exact_correct_predictions.keys()):\n",
    "    correct_count = exact_correct_predictions.get(word, 0)\n",
    "    incorrect_count = incorrect_predictions.get(word, 0)\n",
    "    \n",
    "    print(f\"{word}: {correct_count} / {correct_count + incorrect_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9108d07",
   "metadata": {},
   "source": [
    "### Shorter / Longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee39bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_sentences_by_word_count(references):\n",
    "    \"\"\"Counts the number of sentences by their word count in the given list of texts.\"\"\"\n",
    "    word_count_dict = defaultdict(int)\n",
    "    \n",
    "    for text in references:\n",
    "        cleaned_text = clean_text(text)\n",
    "        sentences = cleaned_text.split('.')\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            words = sentence.split()\n",
    "            if words:  # Only count non-empty sentences\n",
    "                word_count_dict[len(words)] += 1\n",
    "    \n",
    "    return dict(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55dfc50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 145, 4: 17, 2: 18, 3: 39, 5: 11}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = count_sentences_by_word_count(references)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de1fc626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 3, 5, 3, 4, 5, 5, 4, 3, 3, 4, 3, 3, 3, 3, 3, 2, 3, 3, 2, 4, 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdc1673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lengths(lengths, word_count_dict):\n",
    "    \"\"\"Compares the provided lengths list with the word count dictionary.\"\"\"\n",
    "    length_counts = defaultdict(int)\n",
    "    \n",
    "    for length in lengths:\n",
    "        length_counts[length] += 1\n",
    "    \n",
    "    for word_count in sorted(word_count_dict.keys()):\n",
    "        num_sentences = word_count_dict[word_count]\n",
    "        count_in_lengths = length_counts.get(word_count, 0)\n",
    "        print(f'There are {count_in_lengths} out of {num_sentences} that are correct for {word_count}-worded sentences.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86b3aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 out of 145 that are correct for 1-worded sentences.\n",
      "There are 2 out of 18 that are correct for 2-worded sentences.\n",
      "There are 11 out of 39 that are correct for 3-worded sentences.\n",
      "There are 6 out of 17 that are correct for 4-worded sentences.\n",
      "There are 4 out of 11 that are correct for 5-worded sentences.\n"
     ]
    }
   ],
   "source": [
    "compare_lengths(length, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852bed5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0403eff0",
   "metadata": {},
   "source": [
    "## FSL-NMS Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aea9b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = 'T=3, a=0.5/2d_kd_3,0.5.log'  \n",
    "references, hypotheses = extract_data(log_file_path)\n",
    "exact_correct_predictions, loose_correct_predictions, incorrect_predictions, length = analyze_predictions(references, hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "252976b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 170\n"
     ]
    }
   ],
   "source": [
    "print(len(references), len(hypotheses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f3cb038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i   am  sorry.',\n",
       " '* good morning!',\n",
       " 'you are so slow!',\n",
       " 'i am not tired.',\n",
       " 'i am heartbroken.',\n",
       " 'i like you very much.',\n",
       " 'my dog died.',\n",
       " 'i am scared.',\n",
       " 'is it new year?',\n",
       " 'i am worried.',\n",
       " 'this is not  hard.',\n",
       " 'my head is   painful.',\n",
       " 'i am ** ***** sorry.',\n",
       " 'i am   tired.',\n",
       " '* how old are   you?',\n",
       " 'i am ** ***** scared.',\n",
       " '* good morning!',\n",
       " 'i am fine.',\n",
       " 'my dog died.',\n",
       " 'you are disgusting!',\n",
       " 'i ** like you.',\n",
       " 'this is very hard.',\n",
       " 'i am *** tired.',\n",
       " 'i do not like you.',\n",
       " '* john likes mary.',\n",
       " 'i saw a  ghost.',\n",
       " 'i am shocked!',\n",
       " 'you are disgusting!',\n",
       " 'how old are you?',\n",
       " 'i am worried.',\n",
       " 'i am so tired.',\n",
       " 'i am alone.',\n",
       " 'i am ** ***** sorry.',\n",
       " 'i am shocked!',\n",
       " '* the trip  is exciting.',\n",
       " 'you are so slow!',\n",
       " 'i ** ** hate  you!',\n",
       " 'i like you very much.',\n",
       " 'this is hard.',\n",
       " '* does john like  mary?',\n",
       " 'i am sorry.',\n",
       " 'how are you?',\n",
       " 'you are slow.',\n",
       " 'you are sick.',\n",
       " 'my dog died.',\n",
       " '* ** good morning!',\n",
       " 'i saw a  ghost.',\n",
       " '* thank you.',\n",
       " 'i failed the exam.',\n",
       " 'you are slow.',\n",
       " 'you are sick.',\n",
       " 'i am scared.',\n",
       " 'i like you.',\n",
       " 'i am not tired.',\n",
       " 'i am alone.',\n",
       " '* this is not   hard.',\n",
       " 'i ** ** hate  you!',\n",
       " 'i am shocked!',\n",
       " '* ** you are   disgusting!',\n",
       " 'i am ** so    tired.',\n",
       " 'how old are you?',\n",
       " '* ** you are   disgusting!',\n",
       " 'i saw a  ghost.',\n",
       " 'my dog died.',\n",
       " 'our team won!',\n",
       " 'you are not slow.',\n",
       " '* good noon!',\n",
       " 'happy new year!',\n",
       " 'i saw a  ghost.',\n",
       " 'how old are you?',\n",
       " '* you are   so slow!',\n",
       " 'i am fine.',\n",
       " 'i am proud of you!',\n",
       " 'you are slow.',\n",
       " '* how old are   you?',\n",
       " 'you are so slow!',\n",
       " 'i ** hate you!',\n",
       " 'you are not slow.',\n",
       " 'my head is very painful.',\n",
       " 'i failed the exam.',\n",
       " 'john likes mary.',\n",
       " 'i am ***** ** scared.',\n",
       " 'i am ***** ** nervous.',\n",
       " '* good morning!',\n",
       " '* ** how   are you?',\n",
       " 'i like you   very much.',\n",
       " 'i hate you!',\n",
       " '* this is    very hard.',\n",
       " 'you are disgusting!',\n",
       " 'does john like mary?',\n",
       " 'i am alone.',\n",
       " 'i am proud of you!',\n",
       " 'you are sick!',\n",
       " 'this is very hard.',\n",
       " 'i like you.',\n",
       " '* you are so    slow!',\n",
       " '* ** ** good  morning!',\n",
       " 'i do not like  you.',\n",
       " '* my head is    painful.',\n",
       " 'i am nervous.',\n",
       " 'i am 12 years old.',\n",
       " 'john likes mary.',\n",
       " 'i am so tired.',\n",
       " '* ** happy new   year!',\n",
       " 'this is hard.',\n",
       " 'i am sorry.',\n",
       " 'you are sick.',\n",
       " 'i am nervous.',\n",
       " 'you are disgusting!',\n",
       " 'i like you.',\n",
       " 'i am ** ***** tired.',\n",
       " '* you are not   slow.',\n",
       " 'happy new year!',\n",
       " 'how old are you?',\n",
       " '* the trip is    exciting.',\n",
       " 'i am ** ***** ***** ***** nervous.',\n",
       " 'i am ** ***** ***** so    tired.',\n",
       " 'you are sick!',\n",
       " '* thank you.',\n",
       " 'i am worried.',\n",
       " 'i am proud of    you!',\n",
       " '* ** happy new year!',\n",
       " 'i am ** ***** scared.',\n",
       " 'i am ** ***** sorry.',\n",
       " '* you are   not slow.',\n",
       " '* the show is    amazing.',\n",
       " 'you are disgusting!',\n",
       " 'i am ***** ** worried.',\n",
       " '* ** good noon!',\n",
       " '* ** good noon!',\n",
       " 'i am ** not   tired.',\n",
       " 'i am 12 years old.',\n",
       " 'i am shocked!',\n",
       " 'you are sick!',\n",
       " 'my head is not   painful.',\n",
       " 'i ** ** hate  you!',\n",
       " '* ** ***** good noon!',\n",
       " 'i ** saw a     ghost.',\n",
       " 'i am ***** ** tired.',\n",
       " '* the show  is amazing.',\n",
       " 'i am proud of    you!',\n",
       " '* ** ** thank you.',\n",
       " 'i ** ** hate  you!',\n",
       " '* ** my dog   died.',\n",
       " '* ** you are   slow.',\n",
       " 'i am 12 years old.',\n",
       " 'the trip is exciting.',\n",
       " 'i am ** ***** sorry.',\n",
       " 'how old are you?',\n",
       " 'i do not like you.',\n",
       " 'i am nervous.',\n",
       " 'you are disgusting!',\n",
       " 'i hate you!',\n",
       " 'i am fine.',\n",
       " 'is it new year?',\n",
       " 'this is very hard.',\n",
       " 'my dog died.',\n",
       " 'you are sick!',\n",
       " '* thank you.',\n",
       " 'this is hard.',\n",
       " '* ** ***** thank you.',\n",
       " '* ** happy new year!',\n",
       " 'my head is    not painful.',\n",
       " '* ** you are   disgusting!',\n",
       " 'i am ***** ** shocked!',\n",
       " 'i hate you!',\n",
       " 'i am nervous.',\n",
       " 'this is very hard.',\n",
       " 'you are sick!',\n",
       " '* ** my    dog died.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "083ed982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you are sick.',\n",
       " 'i am   fine.',\n",
       " 'you are so slow!',\n",
       " 'i am *** fine.',\n",
       " 'i am fine.',\n",
       " 'i **** *** am   worried.',\n",
       " 'i  am  worried.',\n",
       " 'i am worried.',\n",
       " '** i  am  worried.',\n",
       " 'i am worried.',\n",
       " '**** i  like you.',\n",
       " '** i    like you.',\n",
       " 'i am 12 years old.',\n",
       " 'i like you.',\n",
       " 'i am  12  years old.',\n",
       " 'i am 12 years old.',\n",
       " 'i am   tired.',\n",
       " 'i am fine.',\n",
       " 'i  am  alone.',\n",
       " 'i   am  tired.',\n",
       " 'i am so   tired.',\n",
       " 'i    am not  tired.',\n",
       " 'i am not tired.',\n",
       " 'i am not **** tired.',\n",
       " 'i am   so    tired.',\n",
       " 'i *** am tired.',\n",
       " 'i am fine.',\n",
       " 'i   am  heartbroken.',\n",
       " '*** i   am  fine.',\n",
       " 'i am tired.',\n",
       " 'i am ** heartbroken.',\n",
       " 'i am shocked!',\n",
       " 'i am 12 years old.',\n",
       " 'i am shocked!',\n",
       " 'i am  proud of you!',\n",
       " '*** i   am alone.',\n",
       " 'i am 12 years old.',\n",
       " 'i **** *** am   alone.',\n",
       " 'i    am alone.',\n",
       " 'i am   12   years old.',\n",
       " 'i am tired.',\n",
       " 'i   am  nervous.',\n",
       " 'i   am  alone.',\n",
       " 'i   am  nervous.',\n",
       " 'i  am  tired.',\n",
       " 'i am not  tired.',\n",
       " 'i *** am fine.',\n",
       " 'i am    nervous.',\n",
       " 'i ****** am  sorry.',\n",
       " 'i   am  sorry.',\n",
       " 'i   am  nervous.',\n",
       " 'i am nervous.',\n",
       " 'i am   nervous.',\n",
       " 'i am *** nervous.',\n",
       " 'i am scared.',\n",
       " 'i am   12 years old.',\n",
       " 'i am 12 years old.',\n",
       " 'i am fine.',\n",
       " 'i am 12  years old.',\n",
       " 'i am 12 years old.',\n",
       " '*** i   am  sorry.',\n",
       " 'i am 12  years old.',\n",
       " 'i *** am scared.',\n",
       " 'i  am  scared.',\n",
       " 'i   am   scared.',\n",
       " '*** i   am  alone.',\n",
       " 'i am   tired.',\n",
       " 'i     am  nervous.',\n",
       " 'i *** am alone.',\n",
       " '*** i   am  alone.',\n",
       " 'i am  proud of you!',\n",
       " 'i am shocked!',\n",
       " 'i am proud of you!',\n",
       " 'i   am  heartbroken.',\n",
       " 'i am  12  years old.',\n",
       " '*** i   am nervous.',\n",
       " 'i am so   tired.',\n",
       " '*** i   am  scared.',\n",
       " '** **** i  am   nervous.',\n",
       " 'i am     so  tired.',\n",
       " 'i    am    tired.',\n",
       " 'i am proud of you!',\n",
       " 'i am proud of you!',\n",
       " 'i am   tired.',\n",
       " 'i am proud of  you!',\n",
       " 'i am   proud of   you!',\n",
       " 'i am   nervous.',\n",
       " 'i am   proud of   you!',\n",
       " 'i   am  alone.',\n",
       " '**** i    am   alone.',\n",
       " 'i am fine.',\n",
       " 'i am ***** ** tired.',\n",
       " 'i   am  heartbroken.',\n",
       " '**** i  am   fine.',\n",
       " 'i am   alone.',\n",
       " 'i am  12  years old.',\n",
       " 'i am 12 years old.',\n",
       " 'i am 12  years old.',\n",
       " 'i am 12   years old.',\n",
       " 'i am tired.',\n",
       " 'i am ** ***** tired.',\n",
       " 'i    am    tired.',\n",
       " 'i am ** nervous.',\n",
       " 'i am 12    years old.',\n",
       " 'i    am nervous.',\n",
       " 'i am worried.',\n",
       " 'i   am  nervous.',\n",
       " 'i am heartbroken.',\n",
       " 'i   am  nervous.',\n",
       " 'i am   nervous.',\n",
       " 'i am 12 years old.',\n",
       " 'i am  12  years old.',\n",
       " 'i     am  nervous.',\n",
       " '*** i   am  nervous.',\n",
       " 'i am  12   years old.',\n",
       " 'i am 12 years years years old.',\n",
       " 'i am 12 years years years old.',\n",
       " 'i   am  nervous.',\n",
       " 'i am    nervous.',\n",
       " 'i am nervous.',\n",
       " 'i am 12    years old.',\n",
       " 'i am proud of  you!',\n",
       " 'i am 12 years old.',\n",
       " 'i am 12 years old.',\n",
       " 'i am  proud of  you!',\n",
       " 'i am  12   years old.',\n",
       " 'i   am  nervous.',\n",
       " 'i am proud of you!',\n",
       " 'i am not  tired.',\n",
       " 'i am not  tired.',\n",
       " 'i am 12 years old.',\n",
       " 'i am 12 years old.',\n",
       " 'i am nervous.',\n",
       " 'i   am  nervous.',\n",
       " 'i  am   12 years old.',\n",
       " 'i am 12 years old.',\n",
       " 'i am proud of   you!',\n",
       " 'i am 12  years old.',\n",
       " 'i am proud of you!',\n",
       " 'i am  proud of you!',\n",
       " 'i am 12    years old.',\n",
       " 'i am 12 years old.',\n",
       " 'i am 12 years old.',\n",
       " 'i am 12 years old.',\n",
       " 'i am 12  years old.',\n",
       " 'i am ** ***** alone.',\n",
       " '*** i    am nervous.',\n",
       " 'i am 12 years old.',\n",
       " '*** i   am  nervous.',\n",
       " 'i ** *** am   nervous.',\n",
       " 'i am alone.',\n",
       " 'i   am  heartbroken.',\n",
       " 'i am   tired.',\n",
       " 'i am tired.',\n",
       " '** i  am  alone.',\n",
       " '**** i  am   fine.',\n",
       " 'i  am  fine.',\n",
       " 'i   am  nervous.',\n",
       " 'i am    nervous.',\n",
       " 'i    am nervous.',\n",
       " 'i am proud of    you!',\n",
       " 'i am proud of  you!',\n",
       " 'i  am   proud of  you!',\n",
       " 'i am 12  years old.',\n",
       " 'i am proud of you!',\n",
       " 'i am   alone.',\n",
       " 'i am nervous.',\n",
       " '**** i  am   nervous.',\n",
       " 'i   am  nervous.',\n",
       " 'i am proud of  you!']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5c80990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Correct Predictions:\n",
      "you: 1\n",
      "are: 1\n",
      "so: 1\n",
      "slow!: 1\n",
      "i: 76\n",
      "am: 50\n",
      "worried.: 1\n",
      "fine.: 1\n",
      "tired.: 1\n",
      "not: 1\n",
      "shocked!: 1\n",
      "proud: 1\n",
      "of: 1\n",
      "you!: 1\n",
      "12: 1\n",
      "years: 1\n",
      "old.: 1\n",
      "nervous.: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact Correct Predictions:\")\n",
    "for word, count in exact_correct_predictions.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26c79b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose Correct Predictions (word found anywhere in the sentence):\n",
      "you: 1\n",
      "are: 1\n",
      "so: 1\n",
      "slow!: 1\n",
      "i: 76\n",
      "am: 50\n",
      "worried.: 1\n",
      "fine.: 1\n",
      "tired.: 1\n",
      "not: 1\n",
      "shocked!: 1\n",
      "proud: 1\n",
      "of: 1\n",
      "you!: 1\n",
      "12: 1\n",
      "years: 1\n",
      "old.: 1\n",
      "nervous.: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Loose Correct Predictions (word found anywhere in the sentence):\")\n",
    "for word, count in loose_correct_predictions.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a334c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Incorrect Predictions:\n",
      "i: 1\n",
      "am: 2\n",
      "sorry.: 7\n",
      "*: 39\n",
      "good: 9\n",
      "morning!: 5\n",
      "not: 13\n",
      "tired.: 10\n",
      "heartbroken.: 1\n",
      "like: 12\n",
      "you: 32\n",
      "very: 9\n",
      "much.: 3\n",
      "my: 12\n",
      "dog: 7\n",
      "died.: 7\n",
      "scared.: 5\n",
      "is: 22\n",
      "it: 2\n",
      "new: 7\n",
      "year?: 2\n",
      "this: 10\n",
      "hard.: 10\n",
      "head: 5\n",
      "painful.: 5\n",
      "**: 46\n",
      "*****: 19\n",
      "how: 9\n",
      "old: 7\n",
      "are: 38\n",
      "you?: 9\n",
      "disgusting!: 9\n",
      "you.: 12\n",
      "***: 1\n",
      "do: 3\n",
      "john: 5\n",
      "likes: 3\n",
      "mary.: 3\n",
      "saw: 5\n",
      "a: 5\n",
      "ghost.: 5\n",
      "shocked!: 4\n",
      "worried.: 3\n",
      "so: 8\n",
      "alone.: 3\n",
      "the: 7\n",
      "trip: 3\n",
      "exciting.: 3\n",
      "slow!: 4\n",
      "hate: 8\n",
      "you!: 11\n",
      "does: 2\n",
      "mary?: 2\n",
      "slow.: 8\n",
      "sick.: 3\n",
      "thank: 5\n",
      "failed: 2\n",
      "exam.: 2\n",
      "our: 1\n",
      "team: 1\n",
      "won!: 1\n",
      "noon!: 4\n",
      "happy: 5\n",
      "year!: 5\n",
      "fine.: 2\n",
      "nervous.: 5\n",
      "proud: 3\n",
      "of: 3\n",
      "sick!: 5\n",
      "12: 2\n",
      "years: 2\n",
      "old.: 2\n",
      "show: 2\n",
      "amazing.: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIncorrect Predictions:\")\n",
    "for word, count in incorrect_predictions.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be694259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Correct Predictions / (Correct + Incorrect) for Each Word:\n",
      "shocked!: 1 / 5\n",
      "worried.: 1 / 4\n",
      "12: 1 / 3\n",
      "fine.: 1 / 3\n",
      "tired.: 1 / 11\n",
      "old.: 1 / 3\n",
      "i: 76 / 77\n",
      "so: 1 / 9\n",
      "years: 1 / 3\n",
      "nervous.: 1 / 6\n",
      "of: 1 / 4\n",
      "slow!: 1 / 5\n",
      "proud: 1 / 4\n",
      "you!: 1 / 12\n",
      "am: 50 / 52\n",
      "you: 1 / 33\n",
      "are: 1 / 39\n",
      "not: 1 / 14\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact Correct Predictions / (Correct + Incorrect) for Each Word:\")\n",
    "\n",
    "for word in set(exact_correct_predictions.keys()):\n",
    "    correct_count = exact_correct_predictions.get(word, 0)\n",
    "    incorrect_count = incorrect_predictions.get(word, 0)\n",
    "    \n",
    "    print(f\"{word}: {correct_count} / {correct_count + incorrect_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c0f4e",
   "metadata": {},
   "source": [
    "### Shorter / Longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71679633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_sentences_by_word_count(references):\n",
    "    \"\"\"Counts the number of sentences by their word count in the given list of texts.\"\"\"\n",
    "    word_count_dict = defaultdict(int)\n",
    "    \n",
    "    for text in references:\n",
    "        cleaned_text = clean_text(text)\n",
    "        sentences = cleaned_text.split('.')\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            words = sentence.split()\n",
    "            if words:  # Only count non-empty sentences\n",
    "                word_count_dict[len(words)] += 1\n",
    "    \n",
    "    return dict(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3687e8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 92, 2: 14, 4: 48, 5: 16}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = count_sentences_by_word_count(references)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80265c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbca0f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lengths(lengths, word_count_dict):\n",
    "    \"\"\"Compares the provided lengths list with the word count dictionary.\"\"\"\n",
    "    length_counts = defaultdict(int)\n",
    "    \n",
    "    for length in lengths:\n",
    "        length_counts[length] += 1\n",
    "    \n",
    "    for word_count in sorted(word_count_dict.keys()):\n",
    "        num_sentences = word_count_dict[word_count]\n",
    "        count_in_lengths = length_counts.get(word_count, 0)\n",
    "        print(f'There are {count_in_lengths} out of {num_sentences} that are correct for {word_count}-worded sentences.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c831cc56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 out of 14 that are correct for 2-worded sentences.\n",
      "There are 49 out of 92 that are correct for 3-worded sentences.\n",
      "There are 15 out of 48 that are correct for 4-worded sentences.\n",
      "There are 13 out of 16 that are correct for 5-worded sentences.\n"
     ]
    }
   ],
   "source": [
    "compare_lengths(length, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc80c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bbfa4d7",
   "metadata": {},
   "source": [
    "## FSL-NMS Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e641de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = 'tfl_augmented/2d_unf_logs.log'  \n",
    "references, hypotheses = extract_data(log_file_path)\n",
    "exact_correct_predictions, loose_correct_predictions, incorrect_predictions, length = analyze_predictions(references, hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c1adc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200\n"
     ]
    }
   ],
   "source": [
    "print(len(references), len(hypotheses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "678e8e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am *** sorry.',\n",
       " '* ** good morning!',\n",
       " 'you are so slow!',\n",
       " 'i am not tired.',\n",
       " 'i am *** heartbroken.',\n",
       " 'i like you very much.',\n",
       " 'my dog died.',\n",
       " 'i am scared.',\n",
       " 'is it new year?',\n",
       " 'i am worried.',\n",
       " 'this is not  hard.',\n",
       " 'my head is   painful.',\n",
       " 'i am ** sorry.',\n",
       " 'i am tired.',\n",
       " 'how old are you?',\n",
       " 'i am ** ***** scared.',\n",
       " '* good morning!',\n",
       " 'i am fine.',\n",
       " 'my dog died.',\n",
       " 'you are disgusting!',\n",
       " 'i ** like you.',\n",
       " 'this is very hard.',\n",
       " 'i am tired.',\n",
       " 'i do not like you.',\n",
       " '* john likes mary.',\n",
       " 'i saw a  ghost.',\n",
       " 'i am shocked!',\n",
       " 'you are disgusting!',\n",
       " '* how old   are you?',\n",
       " 'i am worried.',\n",
       " 'i am so tired.',\n",
       " 'i am *** alone.',\n",
       " 'i am ** sorry.',\n",
       " 'i am shocked!',\n",
       " 'the trip is  exciting.',\n",
       " 'you are so slow!',\n",
       " 'i hate you!',\n",
       " 'i like you very much.',\n",
       " 'this is hard.',\n",
       " 'does john like mary?',\n",
       " 'i am sorry.',\n",
       " '* how are you?',\n",
       " '* you are slow.',\n",
       " 'you are sick.',\n",
       " 'my dog died.',\n",
       " '* ** good morning!',\n",
       " 'i saw a  ghost.',\n",
       " '* thank you.',\n",
       " 'i failed the exam.',\n",
       " 'you are slow.',\n",
       " '* you are sick.',\n",
       " 'i am scared.',\n",
       " 'i ** like you.',\n",
       " 'i am not tired.',\n",
       " 'i am alone.',\n",
       " 'this is not hard.',\n",
       " 'i ** hate you!',\n",
       " 'i am ** shocked!',\n",
       " '* ** you are   disgusting!',\n",
       " 'i   am  so tired.',\n",
       " 'how old are you?',\n",
       " '**** you  are  disgusting!',\n",
       " '** i    saw a   ghost.',\n",
       " 'my **** ** dog died.',\n",
       " '** **** our team won!',\n",
       " 'you are not slow.',\n",
       " '* good noon!',\n",
       " 'happy new year!',\n",
       " 'i saw a  ghost.',\n",
       " 'how old are you?',\n",
       " 'you are so  slow!',\n",
       " 'i am fine.',\n",
       " 'i am proud of you!',\n",
       " 'you are slow.',\n",
       " 'how old are you?',\n",
       " 'you are so slow!',\n",
       " 'i ** ***** hate you!',\n",
       " '* you are   not slow.',\n",
       " 'my head is very painful.',\n",
       " 'i ** failed the exam.',\n",
       " 'john likes mary.',\n",
       " 'i am scared.',\n",
       " 'i am nervous.',\n",
       " '* ** ** good  morning!',\n",
       " 'how are you?',\n",
       " 'i like you   very much.',\n",
       " 'i hate you!',\n",
       " 'this is very hard.',\n",
       " '* ** you are   disgusting!',\n",
       " 'does john like mary?',\n",
       " 'i am alone.',\n",
       " 'i am proud of you!',\n",
       " 'you are sick!',\n",
       " 'this is very hard.',\n",
       " 'i like you.',\n",
       " 'you are so slow!',\n",
       " '* good morning!',\n",
       " 'i do not like you.',\n",
       " 'my head is painful.',\n",
       " 'i am nervous.',\n",
       " 'i am 12    years old.',\n",
       " 'john likes mary.',\n",
       " 'i am so tired.',\n",
       " '* happy new year!',\n",
       " 'this is hard.',\n",
       " 'i am sorry.',\n",
       " 'you are sick.',\n",
       " 'i am nervous.',\n",
       " 'you are disgusting!',\n",
       " 'i like you.',\n",
       " 'i am tired.',\n",
       " 'you are not slow.',\n",
       " 'happy new year!',\n",
       " 'how old are you?',\n",
       " 'the trip is exciting.',\n",
       " 'i am ***** ** nervous.',\n",
       " 'i am ** so    tired.',\n",
       " 'you are sick!',\n",
       " '* thank you.',\n",
       " 'i am worried.',\n",
       " 'i am proud of you!',\n",
       " '* happy new year!',\n",
       " 'i am ** ***** scared.',\n",
       " 'i am ** ***** sorry.',\n",
       " 'you are not slow.',\n",
       " '* the show is    amazing.',\n",
       " '* ** you are   disgusting!',\n",
       " 'i am worried.',\n",
       " '* good noon!',\n",
       " '* ** ** good  noon!',\n",
       " 'i am ***** not tired.',\n",
       " 'i am 12 years old.',\n",
       " 'i am shocked!',\n",
       " '* ** you   are sick!',\n",
       " 'my head is not painful.',\n",
       " 'i ** ** hate  you!',\n",
       " '* good noon!',\n",
       " 'i ** saw a     ghost.',\n",
       " 'i am tired.',\n",
       " '* the show  is amazing.',\n",
       " 'i am proud of you!',\n",
       " '* thank you.',\n",
       " 'i hate you!',\n",
       " '* my dog died.',\n",
       " 'you are slow.',\n",
       " 'i am 12 years old.',\n",
       " 'the trip is exciting.',\n",
       " 'i am sorry.',\n",
       " 'how old are you?',\n",
       " 'i do not like you.',\n",
       " 'i am ***** ** nervous.',\n",
       " '* ** you   are disgusting!',\n",
       " 'i ** ***** hate you!',\n",
       " 'i am fine.',\n",
       " '* is it    new year?',\n",
       " 'this is very hard.',\n",
       " 'my dog died.',\n",
       " 'you are sick!',\n",
       " '* thank you.',\n",
       " '* this is  hard.',\n",
       " '* thank you.',\n",
       " 'happy new year!',\n",
       " 'my head is not painful.',\n",
       " 'you are disgusting!',\n",
       " 'i am shocked!',\n",
       " 'i hate you!',\n",
       " 'i am nervous.',\n",
       " 'this is very hard.',\n",
       " 'you are sick!',\n",
       " 'my dog died.',\n",
       " 'does john like mary?',\n",
       " '* john likes mary.',\n",
       " 'i am scared.',\n",
       " 'i am shocked!',\n",
       " 'i am so  tired.',\n",
       " 'i am worried.',\n",
       " 'my head is painful.',\n",
       " 'my dog died.',\n",
       " 'my head is painful.',\n",
       " 'i am ***** ** shocked!',\n",
       " 'i am  not tired.',\n",
       " 'i   am  scared.',\n",
       " 'i am *** alone.',\n",
       " 'my head is not painful.',\n",
       " 'i am alone.',\n",
       " '* ** our   team won!',\n",
       " '* the show  is amazing.',\n",
       " 'how old are you?',\n",
       " 'john likes mary.',\n",
       " 'how old are you?',\n",
       " 'i am sorry.',\n",
       " 'i ** failed the exam.',\n",
       " '* is it    new year?',\n",
       " 'i am worried.',\n",
       " 'i do not like you.',\n",
       " 'i am  not tired.',\n",
       " '* good noon!',\n",
       " 'i am sorry.',\n",
       " 'this is  not hard.',\n",
       " 'our team won!']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afc70904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am not tired.',\n",
       " 'i am not  tired.',\n",
       " 'you are so slow!',\n",
       " 'i am not tired.',\n",
       " 'i am not tired.',\n",
       " 'i **** *** am   tired.',\n",
       " 'i  am  worried.',\n",
       " 'i am worried.',\n",
       " '** i  am  worried.',\n",
       " 'i am tired.',\n",
       " '**** i  like you.',\n",
       " '** i    like you.',\n",
       " 'i am so tired.',\n",
       " 'i am worried.',\n",
       " 'i   am  so  tired.',\n",
       " 'i am 12 years old.',\n",
       " 'i am   fine.',\n",
       " 'i am fine.',\n",
       " 'i  am  fine.',\n",
       " 'i   am  fine.',\n",
       " 'i am so   tired.',\n",
       " '**** i  am   shocked!',\n",
       " 'i am alone.',\n",
       " 'i ** *** am   alone.',\n",
       " 'i am   so    tired.',\n",
       " 'i *** am tired.',\n",
       " 'i am fine.',\n",
       " 'i   am  heartbroken.',\n",
       " 'i am  proud of  you!',\n",
       " 'i am fine.',\n",
       " 'i am ** heartbroken.',\n",
       " 'i am not tired.',\n",
       " 'i am so tired.',\n",
       " 'i am shocked!',\n",
       " 'i   am   not tired.',\n",
       " '*** i   am alone.',\n",
       " 'i am   alone.',\n",
       " 'i **** *** am   alone.',\n",
       " 'i    am alone.',\n",
       " '**** i    am   alone.',\n",
       " 'i am fine.',\n",
       " 'i saw a   ghost.',\n",
       " 'i saw a   ghost.',\n",
       " 'i   am  alone.',\n",
       " 'i  am  fine.',\n",
       " 'i am not  tired.',\n",
       " 'i *** am fine.',\n",
       " 'i am    heartbroken.',\n",
       " 'i ****** am  fine.',\n",
       " 'i   am  fine.',\n",
       " 'i am  so  tired.',\n",
       " 'i am fine.',\n",
       " 'i am so   tired.',\n",
       " 'i am *** nervous.',\n",
       " 'i am fine.',\n",
       " 'i    am so  tired.',\n",
       " 'i am so   tired.',\n",
       " 'i am so tired.',\n",
       " 'i am 12  years old.',\n",
       " 'you are so slow!',\n",
       " '*** i   am  fine.',\n",
       " 'does john like mary?',\n",
       " 'my head is  not painful.',\n",
       " 'my head is not painful.',\n",
       " 'my head is  very painful.',\n",
       " '*** i   am  alone.',\n",
       " 'i am   fine.',\n",
       " 'i     am  fine.',\n",
       " 'i *** am alone.',\n",
       " '*** i   am  alone.',\n",
       " 'i   am  not tired.',\n",
       " 'i am shocked!',\n",
       " 'i am ***** ** tired.',\n",
       " 'i   am  heartbroken.',\n",
       " 'i   am  not tired.',\n",
       " '*** i   am nervous.',\n",
       " 'i am proud of   you!',\n",
       " 'i am  proud of  you!',\n",
       " '** **** i  am   nervous.',\n",
       " 'i am proud  of  you!',\n",
       " 'i    am    tired.',\n",
       " 'i am sorry.',\n",
       " 'i am tired.',\n",
       " 'i am 12 years old.',\n",
       " 'i   am  tired.',\n",
       " 'i am   proud of   you!',\n",
       " 'i am   nervous.',\n",
       " '**** i  am   scared.',\n",
       " 'i am 12  years old.',\n",
       " 'i    am   not  tired.',\n",
       " 'i am fine.',\n",
       " 'i am ***** ** scared.',\n",
       " 'i   am  fine.',\n",
       " '**** i  am   fine.',\n",
       " 'i am   fine.',\n",
       " '*** i   am shocked!',\n",
       " 'i am   tired.',\n",
       " 'i am not **** tired.',\n",
       " '** i    am scared.',\n",
       " 'i am tired.',\n",
       " 'i am proud of    you!',\n",
       " 'i    am    fine.',\n",
       " 'i am ** nervous.',\n",
       " 'i am    not tired.',\n",
       " 'i    am fine.',\n",
       " 'i am worried.',\n",
       " 'i   am  heartbroken.',\n",
       " 'i am heartbroken.',\n",
       " 'i   am  heartbroken.',\n",
       " 'i am   heartbroken.',\n",
       " 'i am alone.',\n",
       " '*** i   am  alone.',\n",
       " 'i     am  heartbroken.',\n",
       " '*** i   am  heartbroken.',\n",
       " '*** i    am alone.',\n",
       " 'i am proud of you!',\n",
       " 'i am 12 years old.',\n",
       " 'i   am  fine.',\n",
       " 'i am    fine.',\n",
       " 'i am fine.',\n",
       " 'i am ***** so tired.',\n",
       " 'i am    so  tired.',\n",
       " 'i am 12 years old.',\n",
       " 'i am 12 years old.',\n",
       " 'i   am  so  tired.',\n",
       " 'i am  12   years old.',\n",
       " 'i am 12  years old.',\n",
       " 'i am worried.',\n",
       " 'i am   worried.',\n",
       " 'i am 12 years old.',\n",
       " 'i am proud of  you!',\n",
       " 'i am ** ***** heartbroken.',\n",
       " 'i am fine.',\n",
       " 'i am proud of  you!',\n",
       " '** **** i  am  heartbroken.',\n",
       " 'i am 12 years old.',\n",
       " 'i am   shocked!',\n",
       " 'i am 12  years old.',\n",
       " 'i am sorry.',\n",
       " 'i am  proud of you!',\n",
       " 'i am ***** ** shocked!',\n",
       " 'i am    shocked!',\n",
       " 'i am   alone.',\n",
       " 'i am not tired.',\n",
       " 'i   am  sorry.',\n",
       " 'i am ** ***** tired.',\n",
       " '*** i    am fine.',\n",
       " 'i am alone.',\n",
       " '*** i   am  nervous.',\n",
       " 'i ** *** am   fine.',\n",
       " 'i am proud of you!',\n",
       " 'i am proud of  you!',\n",
       " 'i am proud of   you!',\n",
       " 'i am fine.',\n",
       " 'i am proud of  you!',\n",
       " '**** i  am   fine.',\n",
       " 'i  am  fine.',\n",
       " 'i   am  fine.',\n",
       " 'i am    nervous.',\n",
       " 'i am   not tired.',\n",
       " 'i am    nervous.',\n",
       " 'i     am  nervous.',\n",
       " '** **** i  am  fine.',\n",
       " 'i   am  nervous.',\n",
       " 'i am fine.',\n",
       " 'i am   tired.',\n",
       " 'i am nervous.',\n",
       " '**** i  am   fine.',\n",
       " 'i   am  fine.',\n",
       " 'i  am  tired.',\n",
       " '**** i    am   nervous.',\n",
       " 'i am   not   tired.',\n",
       " 'i am nervous.',\n",
       " 'i am nervous.',\n",
       " 'i am not tired.',\n",
       " 'i am fine.',\n",
       " '** i    am nervous.',\n",
       " 'i  am  fine.',\n",
       " '** i    am nervous.',\n",
       " 'i am proud of you!',\n",
       " '* you are sick!',\n",
       " 'you are sick!',\n",
       " 'i am not tired.',\n",
       " '** **** i  am  nervous.',\n",
       " 'i am fine.',\n",
       " 'i am proud of   you!',\n",
       " 'i am  proud of you!',\n",
       " '*** you are sick!',\n",
       " 'i    am    tired.',\n",
       " '*** i   am  shocked!',\n",
       " 'i am tired.',\n",
       " 'i am proud  of  you!',\n",
       " 'i am proud of  you!',\n",
       " 'i am tired.',\n",
       " 'i ** *** am   tired.',\n",
       " '* you are disgusting!',\n",
       " 'i am   sorry.',\n",
       " 'i am scared.',\n",
       " 'you  are not slow.',\n",
       " 'you are  disgusting!']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "459bc5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Correct Predictions:\n",
      "i: 87\n",
      "am: 61\n",
      "you: 1\n",
      "are: 2\n",
      "so: 2\n",
      "slow!: 1\n",
      "not: 3\n",
      "tired.: 2\n",
      "fine.: 2\n",
      "shocked!: 1\n",
      "my: 1\n",
      "you!: 2\n",
      "worried.: 1\n",
      "nervous.: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact Correct Predictions:\")\n",
    "for word, count in exact_correct_predictions.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ee81c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose Correct Predictions (word found anywhere in the sentence):\n",
      "i: 87\n",
      "am: 61\n",
      "you: 1\n",
      "are: 2\n",
      "so: 2\n",
      "slow!: 1\n",
      "not: 3\n",
      "tired.: 2\n",
      "fine.: 2\n",
      "shocked!: 1\n",
      "my: 1\n",
      "you!: 2\n",
      "worried.: 1\n",
      "nervous.: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Loose Correct Predictions (word found anywhere in the sentence):\")\n",
    "for word, count in loose_correct_predictions.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76c283fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Incorrect Predictions:\n",
      "***: 4\n",
      "sorry.: 9\n",
      "*: 37\n",
      "**: 35\n",
      "good: 10\n",
      "morning!: 5\n",
      "heartbroken.: 1\n",
      "like: 14\n",
      "you: 32\n",
      "very: 9\n",
      "much.: 3\n",
      "my: 15\n",
      "dog: 8\n",
      "died.: 8\n",
      "scared.: 7\n",
      "is: 28\n",
      "it: 3\n",
      "new: 8\n",
      "year?: 3\n",
      "worried.: 5\n",
      "this: 11\n",
      "not: 16\n",
      "hard.: 11\n",
      "head: 8\n",
      "painful.: 8\n",
      "tired.: 12\n",
      "how: 11\n",
      "old: 9\n",
      "are: 39\n",
      "you?: 11\n",
      "*****: 9\n",
      "disgusting!: 9\n",
      "you.: 13\n",
      "do: 4\n",
      "john: 8\n",
      "likes: 5\n",
      "mary.: 5\n",
      "saw: 5\n",
      "a: 5\n",
      "ghost.: 5\n",
      "shocked!: 6\n",
      "so: 8\n",
      "alone.: 5\n",
      "the: 9\n",
      "trip: 3\n",
      "exciting.: 3\n",
      "slow!: 4\n",
      "hate: 8\n",
      "you!: 10\n",
      "does: 3\n",
      "mary?: 3\n",
      "slow.: 8\n",
      "sick.: 3\n",
      "thank: 5\n",
      "failed: 3\n",
      "exam.: 3\n",
      "i: 5\n",
      "am: 4\n",
      "****: 3\n",
      "our: 3\n",
      "team: 3\n",
      "won!: 3\n",
      "noon!: 5\n",
      "happy: 5\n",
      "year!: 5\n",
      "fine.: 1\n",
      "proud: 4\n",
      "of: 4\n",
      "nervous.: 5\n",
      "sick!: 5\n",
      "12: 3\n",
      "years: 3\n",
      "old.: 3\n",
      "show: 3\n",
      "amazing.: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIncorrect Predictions:\")\n",
    "for word, count in incorrect_predictions.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8a343c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Correct Predictions / (Correct + Incorrect) for Each Word:\n",
      "my: 1 / 16\n",
      "shocked!: 1 / 7\n",
      "worried.: 1 / 6\n",
      "tired.: 2 / 14\n",
      "fine.: 2 / 3\n",
      "i: 87 / 92\n",
      "so: 2 / 10\n",
      "nervous.: 1 / 6\n",
      "slow!: 1 / 5\n",
      "you!: 2 / 12\n",
      "am: 61 / 65\n",
      "you: 1 / 33\n",
      "are: 2 / 41\n",
      "not: 3 / 19\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact Correct Predictions / (Correct + Incorrect) for Each Word:\")\n",
    "\n",
    "for word in set(exact_correct_predictions.keys()):\n",
    "    correct_count = exact_correct_predictions.get(word, 0)\n",
    "    incorrect_count = incorrect_predictions.get(word, 0)\n",
    "    \n",
    "    print(f\"{word}: {correct_count} / {correct_count + incorrect_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b531584",
   "metadata": {},
   "source": [
    "### Shorter / Longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b83ad11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_sentences_by_word_count(references):\n",
    "    \"\"\"Counts the number of sentences by their word count in the given list of texts.\"\"\"\n",
    "    word_count_dict = defaultdict(int)\n",
    "    \n",
    "    for text in references:\n",
    "        cleaned_text = clean_text(text)\n",
    "        sentences = cleaned_text.split('.')\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            words = sentence.split()\n",
    "            if words:  # Only count non-empty sentences\n",
    "                word_count_dict[len(words)] += 1\n",
    "    \n",
    "    return dict(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c55abe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 107, 2: 15, 4: 60, 5: 18}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = count_sentences_by_word_count(references)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e844a126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "679b0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lengths(lengths, word_count_dict):\n",
    "    \"\"\"Compares the provided lengths list with the word count dictionary.\"\"\"\n",
    "    length_counts = defaultdict(int)\n",
    "    \n",
    "    for length in lengths:\n",
    "        length_counts[length] += 1\n",
    "    \n",
    "    for word_count in sorted(word_count_dict.keys()):\n",
    "        num_sentences = word_count_dict[word_count]\n",
    "        count_in_lengths = length_counts.get(word_count, 0)\n",
    "        print(f'There are {count_in_lengths} out of {num_sentences} that are correct for {word_count}-worded sentences.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15dbdd79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 out of 15 that are correct for 2-worded sentences.\n",
      "There are 60 out of 107 that are correct for 3-worded sentences.\n",
      "There are 18 out of 60 that are correct for 4-worded sentences.\n",
      "There are 14 out of 18 that are correct for 5-worded sentences.\n"
     ]
    }
   ],
   "source": [
    "compare_lengths(length, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dbc36f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4a66e4c",
   "metadata": {},
   "source": [
    "## Combined Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "697f567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = 'tfl_augmented/combined_unf_logs.log'  \n",
    "references, hypotheses = extract_data(log_file_path)\n",
    "exact_correct_predictions, loose_correct_predictions, incorrect_predictions, length = analyze_predictions(references, hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c6d5f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 60\n"
     ]
    }
   ],
   "source": [
    "print(len(references), len(hypotheses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02b186a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['**** saturday',\n",
       " '**** yellow',\n",
       " '**** mother',\n",
       " '**** october',\n",
       " '* the show  is amazing.',\n",
       " 'person in a  wheelchair',\n",
       " '* ** february',\n",
       " '* good noon!',\n",
       " 'i am fine',\n",
       " '* ** married',\n",
       " '* ** ** ***** blind',\n",
       " '* ** ** ***** slow',\n",
       " '* ** how are   you',\n",
       " '**** son',\n",
       " '**** white',\n",
       " '**** daughter',\n",
       " '**** beer',\n",
       " '**** yesterday',\n",
       " '**** father',\n",
       " '**** monday',\n",
       " '**** green',\n",
       " '**** meat',\n",
       " '**** dark',\n",
       " '**** white',\n",
       " '**** two',\n",
       " '* ** brown',\n",
       " '* ** tomorrow',\n",
       " '* no sugar',\n",
       " 'i saw a  ghost.',\n",
       " '* good morning',\n",
       " 'my dog died.',\n",
       " 'brown',\n",
       " 'fish',\n",
       " 'i like you very much.',\n",
       " 'red',\n",
       " '**** tuesday',\n",
       " '**** juice',\n",
       " '**** september',\n",
       " '**** understand',\n",
       " '**** mother',\n",
       " '**** april',\n",
       " '**** mother',\n",
       " '**** pink',\n",
       " 'do not  know',\n",
       " '**** spaghetti',\n",
       " '* ** ten',\n",
       " 'i ** hate you!',\n",
       " 'how are you?',\n",
       " '* happy new year!',\n",
       " 'our team won!',\n",
       " '**** brown',\n",
       " '**** chicken',\n",
       " 'i do not like you.',\n",
       " 'i am   scared.',\n",
       " '**** violet',\n",
       " 'i am   nervous.',\n",
       " '**** auntie',\n",
       " '**** six',\n",
       " 'i like you very much.',\n",
       " '**** woman']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "222186e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'i am  proud of you!',\n",
       " '****** i  am heartbroken.',\n",
       " 'i am heartbroken.',\n",
       " 'i am   heartbroken.',\n",
       " 'i am heartbroken.',\n",
       " 'i am heartbroken.',\n",
       " 'i am 12 years old.',\n",
       " 'i am 12 years old.',\n",
       " 'i am 12  years old.',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i am fine',\n",
       " 'i *** am scared.',\n",
       " 'i am   fine',\n",
       " 'i  am  fine',\n",
       " 'fast',\n",
       " 'fast',\n",
       " 'i **** *** am   shocked!',\n",
       " 'fast',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'good evening',\n",
       " 'good evening',\n",
       " 'good evening',\n",
       " '** good evening',\n",
       " 'good evening',\n",
       " 'i am fine',\n",
       " 'i am so   tired.',\n",
       " 'i   am  worried.',\n",
       " 'i am    so  tired.',\n",
       " 'i   am   worried.',\n",
       " 'good afternoon',\n",
       " 'good afternoon',\n",
       " 'i ** *** am   fine.',\n",
       " '* good afternoon',\n",
       " 'good afternoon',\n",
       " '* good morning!',\n",
       " 'good evening',\n",
       " 'good evening',\n",
       " '* **** *** good noon!',\n",
       " 'good evening']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "837e1c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Correct Predictions:\n",
      "i: 5\n",
      "am: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact Correct Predictions:\")\n",
    "for word, count in exact_correct_predictions.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bac693ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose Correct Predictions (word found anywhere in the sentence):\n",
      "i: 5\n",
      "am: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Loose Correct Predictions (word found anywhere in the sentence):\")\n",
    "for word, count in loose_correct_predictions.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7382a64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Incorrect Predictions:\n",
      "****: 31\n",
      "saturday: 1\n",
      "yellow: 1\n",
      "mother: 3\n",
      "october: 1\n",
      "*: 13\n",
      "the: 1\n",
      "show: 1\n",
      "is: 1\n",
      "amazing.: 1\n",
      "person: 1\n",
      "in: 1\n",
      "a: 2\n",
      "wheelchair: 1\n",
      "**: 11\n",
      "february: 1\n",
      "good: 2\n",
      "noon!: 1\n",
      "fine: 1\n",
      "married: 1\n",
      "*****: 2\n",
      "blind: 1\n",
      "slow: 1\n",
      "how: 2\n",
      "are: 2\n",
      "you: 3\n",
      "son: 1\n",
      "white: 2\n",
      "daughter: 1\n",
      "beer: 1\n",
      "yesterday: 1\n",
      "father: 1\n",
      "monday: 1\n",
      "green: 1\n",
      "meat: 1\n",
      "dark: 1\n",
      "two: 1\n",
      "brown: 3\n",
      "tomorrow: 1\n",
      "no: 1\n",
      "sugar: 1\n",
      "saw: 1\n",
      "ghost.: 1\n",
      "morning: 1\n",
      "my: 1\n",
      "dog: 1\n",
      "died.: 1\n",
      "fish: 1\n",
      "like: 3\n",
      "very: 2\n",
      "much.: 2\n",
      "red: 1\n",
      "tuesday: 1\n",
      "juice: 1\n",
      "september: 1\n",
      "understand: 1\n",
      "april: 1\n",
      "pink: 1\n",
      "do: 2\n",
      "not: 2\n",
      "know: 1\n",
      "spaghetti: 1\n",
      "ten: 1\n",
      "hate: 1\n",
      "you!: 1\n",
      "you?: 1\n",
      "happy: 1\n",
      "new: 1\n",
      "year!: 1\n",
      "our: 1\n",
      "team: 1\n",
      "won!: 1\n",
      "chicken: 1\n",
      "you.: 1\n",
      "i: 3\n",
      "am: 2\n",
      "scared.: 1\n",
      "violet: 1\n",
      "nervous.: 1\n",
      "auntie: 1\n",
      "six: 1\n",
      "woman: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIncorrect Predictions:\")\n",
    "for word, count in incorrect_predictions.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "006ad0c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Correct Predictions / (Correct + Incorrect) for Each Word:\n",
      "i: 5 / 8\n",
      "am: 1 / 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact Correct Predictions / (Correct + Incorrect) for Each Word:\")\n",
    "\n",
    "for word in set(exact_correct_predictions.keys()):\n",
    "    correct_count = exact_correct_predictions.get(word, 0)\n",
    "    incorrect_count = incorrect_predictions.get(word, 0)\n",
    "    \n",
    "    print(f\"{word}: {correct_count} / {correct_count + incorrect_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e3fa0a",
   "metadata": {},
   "source": [
    "### Shorter / Longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "746669f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_sentences_by_word_count(references):\n",
    "    \"\"\"Counts the number of sentences by their word count in the given list of texts.\"\"\"\n",
    "    word_count_dict = defaultdict(int)\n",
    "    \n",
    "    for text in references:\n",
    "        cleaned_text = clean_text(text)\n",
    "        sentences = cleaned_text.split('.')\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            words = sentence.split()\n",
    "            if words:  # Only count non-empty sentences\n",
    "                word_count_dict[len(words)] += 1\n",
    "    \n",
    "    return dict(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd29903c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 41, 4: 3, 2: 3, 3: 10, 5: 3}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = count_sentences_by_word_count(references)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c8b3fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 3, 5]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "864c405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lengths(lengths, word_count_dict):\n",
    "    \"\"\"Compares the provided lengths list with the word count dictionary.\"\"\"\n",
    "    length_counts = defaultdict(int)\n",
    "    \n",
    "    for length in lengths:\n",
    "        length_counts[length] += 1\n",
    "    \n",
    "    for word_count in sorted(word_count_dict.keys()):\n",
    "        num_sentences = word_count_dict[word_count]\n",
    "        count_in_lengths = length_counts.get(word_count, 0)\n",
    "        print(f'There are {count_in_lengths} out of {num_sentences} that are correct for {word_count}-worded sentences.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74d5257a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 out of 41 that are correct for 1-worded sentences.\n",
      "There are 0 out of 3 that are correct for 2-worded sentences.\n",
      "There are 2 out of 10 that are correct for 3-worded sentences.\n",
      "There are 1 out of 3 that are correct for 4-worded sentences.\n",
      "There are 2 out of 3 that are correct for 5-worded sentences.\n"
     ]
    }
   ],
   "source": [
    "compare_lengths(length, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281691f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba35725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f58201d4",
   "metadata": {},
   "source": [
    "# Predictions per N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "900f3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "\n",
    "# Function to extract data from the log file\n",
    "def extract_data(log_file_path: str) -> Tuple[List[str], List[str]]:\n",
    "    with open(log_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    references = []\n",
    "    hypotheses = []\n",
    "    \n",
    "    for i in range(len(lines) - 1):\n",
    "        if 'Text Reference' in lines[i]:\n",
    "            reference_part = lines[i].split(':\\t', 1)[1].strip()\n",
    "            hypothesis_part = lines[i + 1].split(':\\t', 1)[1].strip()\n",
    "            references.append(reference_part)\n",
    "            hypotheses.append(hypothesis_part)\n",
    "    \n",
    "    return references, hypotheses\n",
    "\n",
    "# Function to clean text by removing non-alphanumeric characters except spaces\n",
    "def clean_text(text: str) -> str:\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d04efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Function to generate n-grams from a given text\n",
    "def generate_ngrams(text: str, n: int) -> List[str]:\n",
    "    words = text.split()\n",
    "    ngrams = [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "    return ngrams\n",
    "\n",
    "# Function to analyze and count correct predictions per n-gram\n",
    "def analyze_predictions(references: List[str], hypotheses: List[str], n: int) -> Counter:\n",
    "    correct_ngrams = Counter()\n",
    "    total_ngrams = Counter()\n",
    "    \n",
    "    for reference, hypothesis in zip(references, hypotheses):\n",
    "        ref_ngrams = generate_ngrams(reference, n)\n",
    "        hyp_ngrams = generate_ngrams(hypothesis, n)\n",
    "        \n",
    "        total_ngrams.update(ref_ngrams)\n",
    "        \n",
    "        for ngram in hyp_ngrams:\n",
    "            if ngram in ref_ngrams:\n",
    "                correct_ngrams[ngram] += 1\n",
    "    \n",
    "    return correct_ngrams, total_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f31c91",
   "metadata": {},
   "source": [
    "## Combined Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19f1ed9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions Per 1-gram:\n",
      "       Count\n",
      "i         21\n",
      "am        15\n",
      "proud      1\n",
      "of         1\n",
      "you        3\n",
      "fine       1\n",
      "no         1\n",
      "good       1\n",
      "\n",
      "\n",
      "Correct Predictions Per 2-gram:\n",
      "          Count\n",
      "i am         15\n",
      "am proud      1\n",
      "proud of      1\n",
      "of you        1\n",
      "am fine       1\n",
      "\n",
      "\n",
      "Correct Predictions Per 3-gram:\n",
      "              Count\n",
      "i am proud        1\n",
      "am proud of       1\n",
      "proud of you      1\n",
      "i am fine         1\n",
      "\n",
      "\n",
      "Correct Predictions Per 4-gram:\n",
      "                 Count\n",
      "i am proud of        1\n",
      "am proud of you      1\n",
      "\n",
      "\n",
      "Correct Predictions Per 5-gram:\n",
      "                   Count\n",
      "i am proud of you      1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the log file (update with the actual path if necessary)\n",
    "log_file_path = 'T=3, a=0.5/combined_kd_3,0.5.log'  # Update with the correct path\n",
    "\n",
    "# Extract and clean data\n",
    "references, hypotheses = extract_data(log_file_path)\n",
    "references = [clean_text(ref) for ref in references]\n",
    "hypotheses = [clean_text(hyp) for hyp in hypotheses]\n",
    "\n",
    "# Loop through n-grams from 1 to 5 and analyze predictions\n",
    "results = {}\n",
    "for n in range(1, 6):\n",
    "    correct_ngrams, total_ngrams = analyze_predictions(references, hypotheses, n)\n",
    "    df_correct_ngrams = pd.DataFrame.from_dict(correct_ngrams, orient='index', columns=['Count'])\n",
    "    results[f'{n}-gram'] = df_correct_ngrams\n",
    "\n",
    "# Display the results for each n-gram\n",
    "for n in range(1, 6):\n",
    "    print(f\"Correct Predictions Per {n}-gram:\")\n",
    "    print(results[f'{n}-gram'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f843281e",
   "metadata": {},
   "source": [
    "## FSL-NMS Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f37757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions Per 1-gram:\n",
      "         Count\n",
      "you          7\n",
      "are          1\n",
      "so           1\n",
      "slow         1\n",
      "i           76\n",
      "am          50\n",
      "worried      1\n",
      "old          3\n",
      "fine         1\n",
      "tired        1\n",
      "not          1\n",
      "shocked      1\n",
      "proud        1\n",
      "of           1\n",
      "12           1\n",
      "years        1\n",
      "nervous      1\n",
      "\n",
      "\n",
      "Correct Predictions Per 2-gram:\n",
      "            Count\n",
      "you are         1\n",
      "are so          1\n",
      "so slow         1\n",
      "i am           50\n",
      "am worried      1\n",
      "am fine         1\n",
      "am shocked      1\n",
      "am proud        1\n",
      "proud of        1\n",
      "of you          1\n",
      "am 12           1\n",
      "12 years        1\n",
      "years old       1\n",
      "am nervous      1\n",
      "\n",
      "\n",
      "Correct Predictions Per 3-gram:\n",
      "              Count\n",
      "you are so        1\n",
      "are so slow       1\n",
      "i am worried      1\n",
      "i am fine         1\n",
      "i am shocked      1\n",
      "i am proud        1\n",
      "am proud of       1\n",
      "proud of you      1\n",
      "i am 12           1\n",
      "am 12 years       1\n",
      "12 years old      1\n",
      "i am nervous      1\n",
      "\n",
      "\n",
      "Correct Predictions Per 4-gram:\n",
      "                 Count\n",
      "you are so slow      1\n",
      "i am proud of        1\n",
      "am proud of you      1\n",
      "i am 12 years        1\n",
      "am 12 years old      1\n",
      "\n",
      "\n",
      "Correct Predictions Per 5-gram:\n",
      "                   Count\n",
      "i am proud of you      1\n",
      "i am 12 years old      1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the log file (update with the actual path if necessary)\n",
    "log_file_path = 'T=3, a=0.5/2d_kd_3,0.5.log'  # Update with the correct path\n",
    "\n",
    "# Extract and clean data\n",
    "references, hypotheses = extract_data(log_file_path)\n",
    "references = [clean_text(ref) for ref in references]\n",
    "hypotheses = [clean_text(hyp) for hyp in hypotheses]\n",
    "\n",
    "# Loop through n-grams from 1 to 5 and analyze predictions\n",
    "results = {}\n",
    "for n in range(1, 6):\n",
    "    correct_ngrams, total_ngrams = analyze_predictions(references, hypotheses, n)\n",
    "    df_correct_ngrams = pd.DataFrame.from_dict(correct_ngrams, orient='index', columns=['Count'])\n",
    "    results[f'{n}-gram'] = df_correct_ngrams\n",
    "\n",
    "# Display the results for each n-gram\n",
    "for n in range(1, 6):\n",
    "    print(f\"Correct Predictions Per {n}-gram:\")\n",
    "    print(results[f'{n}-gram'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2554ae",
   "metadata": {},
   "source": [
    "## Combined Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36865026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions Per 1-gram:\n",
      "    Count\n",
      "i       5\n",
      "am      1\n",
      "\n",
      "\n",
      "Correct Predictions Per 2-gram:\n",
      "      Count\n",
      "i am      1\n",
      "\n",
      "\n",
      "Correct Predictions Per 3-gram:\n",
      "Empty DataFrame\n",
      "Columns: [Count]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Correct Predictions Per 4-gram:\n",
      "Empty DataFrame\n",
      "Columns: [Count]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Correct Predictions Per 5-gram:\n",
      "Empty DataFrame\n",
      "Columns: [Count]\n",
      "Index: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the log file (update with the actual path if necessary)\n",
    "log_file_path = 'tfl_augmented/combined_unf_logs.log' \n",
    "\n",
    "# Extract and clean data\n",
    "references, hypotheses = extract_data(log_file_path)\n",
    "references = [clean_text(ref) for ref in references]\n",
    "hypotheses = [clean_text(hyp) for hyp in hypotheses]\n",
    "\n",
    "# Loop through n-grams from 1 to 5 and analyze predictions\n",
    "results = {}\n",
    "for n in range(1, 6):\n",
    "    correct_ngrams, total_ngrams = analyze_predictions(references, hypotheses, n)\n",
    "    df_correct_ngrams = pd.DataFrame.from_dict(correct_ngrams, orient='index', columns=['Count'])\n",
    "    results[f'{n}-gram'] = df_correct_ngrams\n",
    "\n",
    "# Display the results for each n-gram\n",
    "for n in range(1, 6):\n",
    "    print(f\"Correct Predictions Per {n}-gram:\")\n",
    "    print(results[f'{n}-gram'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e87c78",
   "metadata": {},
   "source": [
    "## FSL-NMS Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd72322f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions Per 1-gram:\n",
      "         Count\n",
      "i           87\n",
      "am          61\n",
      "you          9\n",
      "are          2\n",
      "so           2\n",
      "slow         1\n",
      "not          3\n",
      "tired        2\n",
      "fine         2\n",
      "shocked      1\n",
      "my           1\n",
      "worried      1\n",
      "nervous      1\n",
      "\n",
      "\n",
      "Correct Predictions Per 2-gram:\n",
      "            Count\n",
      "i am           61\n",
      "you are         1\n",
      "are so          1\n",
      "so slow         1\n",
      "am not          1\n",
      "not tired       1\n",
      "am fine         2\n",
      "am shocked      1\n",
      "am worried      1\n",
      "am nervous      1\n",
      "\n",
      "\n",
      "Correct Predictions Per 3-gram:\n",
      "              Count\n",
      "you are so        1\n",
      "are so slow       1\n",
      "i am not          1\n",
      "am not tired      1\n",
      "i am fine         2\n",
      "i am shocked      1\n",
      "i am worried      1\n",
      "i am nervous      1\n",
      "\n",
      "\n",
      "Correct Predictions Per 4-gram:\n",
      "                 Count\n",
      "you are so slow      1\n",
      "i am not tired       1\n",
      "\n",
      "\n",
      "Correct Predictions Per 5-gram:\n",
      "Empty DataFrame\n",
      "Columns: [Count]\n",
      "Index: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the log file (update with the actual path if necessary)\n",
    "log_file_path = 'tfl_augmented/2d_unf_logs.log' \n",
    "\n",
    "# Extract and clean data\n",
    "references, hypotheses = extract_data(log_file_path)\n",
    "references = [clean_text(ref) for ref in references]\n",
    "hypotheses = [clean_text(hyp) for hyp in hypotheses]\n",
    "\n",
    "# Loop through n-grams from 1 to 5 and analyze predictions\n",
    "results = {}\n",
    "for n in range(1, 6):\n",
    "    correct_ngrams, total_ngrams = analyze_predictions(references, hypotheses, n)\n",
    "    df_correct_ngrams = pd.DataFrame.from_dict(correct_ngrams, orient='index', columns=['Count'])\n",
    "    results[f'{n}-gram'] = df_correct_ngrams\n",
    "\n",
    "# Display the results for each n-gram\n",
    "for n in range(1, 6):\n",
    "    print(f\"Correct Predictions Per {n}-gram:\")\n",
    "    print(results[f'{n}-gram'])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
